import whisperx
import torch
import gc  # Optional: for GPU memory cleanup

# --- User Configuration ---
audio_file = "test.wav"  # Specify input audio file path
output_dir = "dir"  # Optional: specify output directory
device = "cuda" if torch.cuda.is_available() else "cpu"  # Auto-detect CUDA
batch_size = 16  # Adjust based on GPU memory (e.g., 8, 16, 24)
compute_type = "float16"  # Options: "float16", "int8", "float32"
whisper_model_name = "large-v3-turbo"  # Recommended: "large-v3". Others: "large-v2", "medium.en", "small.en", "base.en", "tiny.en"
language_code = "en"  # Set language code


vad_options = {
    "vad_threshold": 0.1,  # Mapped: sensitive VAD
    "min_silence_duration_ms": 50,  # Mapped: 0.05s
    # -- Optional VAD parameters (defaults often fine) --
    # "min_speech_duration_ms": 250,
    # "speech_pad_ms": 30,
}

# 2. Whisper ASR Model Configuration (asr_options for faster-whisper)
# Migrating settings focused on capturing low-confidence words
asr_options = {
    # --- Core settings for sensitivity ---
    "log_prob_threshold": -2.0,  # Allow low prob tokens
    "no_speech_threshold": 0.15,  # Sensitive speech detection
    "temperatures": [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],  # Temp fallback
    "condition_on_previous_text": True,  # Use context
    "compression_ratio_threshold": 100.0,  # Disable compression filter
    "word_timestamps": True,  # Must be True for alignment
    "without_timestamps": False,  # Ensure timestamps are generated
    # --- Standard FasterWhisper settings (Defaults or reasonable choices) ---
    "beam_size": 5,  # Default beam search
    "best_of": 5,  # Select best from beams
    "patience": 1.0,  # Default beam search patience
    "length_penalty": 1.0,  # Default length penalty
    "repetition_penalty": 1.0,  # Default repetition penalty
    "no_repeat_ngram_size": 0,  # Default ngram repetition check
    "prompt_reset_on_temperature": 0.5,  # Default temp reset behavior
    "initial_prompt": None,  # No initial prompt
    "prefix": None,  # No prefix
    "suppress_blank": True,  # Suppress blank tokens
    "suppress_tokens": [-1],  # Default token suppression
    "max_initial_timestamp": 0.0,  # Default initial timestamp
    "prepend_punctuations": "\"'“¿([{-",  # Default punctuation handling
    "append_punctuations": "\"'.。,，!！?？:：”)]}、",  # Default punctuation handling
    "suppress_numerals": False,  # Keep numerals
    "max_new_tokens": None,  # No restriction on new tokens
    "clip_timestamps": None,  # No explicit clipping
    "hallucination_silence_threshold": None,  # Disable hallucination filter
    "hotwords": None,  # No specific hotwords
}

print("Alignment model loaded.")


# --- Main Execution ---

# 1. Load Whisper Model with VAD and ASR options
print(f"Loading Whisper model: {whisper_model_name}...")
model = whisperx.load_model(
    whisper_model_name,
    device,
    compute_type=compute_type,
    language=language_code,  # Optional: specify language during load
    asr_options=asr_options,
    vad_model=whisperx.vad.load_vad_model(device),  # Provide the loaded VAD model
    vad_options=vad_options,  # Provide VAD parameters
    task="transcribe",  # Explicitly set task
    # download_root=None, # Optional: specify model download path
    # threads=4 # Optional: CPU threads for tokenizer
)
print("Whisper model loaded.")

# 2. Load Audio
# Ensure audio is in a format Whisper can handle (e.g., wav, mp3)
print(f"Loading audio: {audio_file}...")
audio = whisperx.load_audio(audio_file)
print("Audio loaded.")

# 3. Transcribe Audio
# This step uses the loaded model and integrated VAD
print("Starting transcription...")
transcribe_config = {
    "batch_size": batch_size,
    "language": language_code,  # Can override language here if needed
    "chunk_size": 30,  # Process audio in 30-second chunks
    "print_progress": True,  # Show transcription progress bar
    # "verbose": None # Controls faster-whisper internal verbosity (default None)
}
result = model.transcribe(audio, **transcribe_config)
print("Transcription finished.")
# 'result' contains segments with word timestamps generated by faster-whisper

# 3. Alignment Model Configuration
# This model refines word timings after initial transcription
print("Loading alignment model...")
align_model, align_metadata = whisperx.load_align_model(
    language_code=language_code, device=device
)
align_config = {
    "model": align_model,
    "align_model_metadata": align_metadata,
    "device": device,
    "return_char_alignments": False,  # Keep False unless char-level needed
    "print_progress": True,  # Show alignment progress bar
    # "interpolate_method": "nearest", # Default method
}
print("Starting alignment...")
result_aligned = whisperx.align(result["segments"], audio=audio, **align_config)
print("Alignment finished.")
print("\nAligned Word Segments:")
for segment in result_aligned["segments"]:
    for word in segment["words"]:
        start = word.get('start', None)
        end = word.get('end', None)
        score = word.get('score', None)
        print(f"[{start:.2f}s -> {end:.2f}s] {word['word']} (Score: {score:.2f})")

print("Cleaning up models...")
del model
del align_model
gc.collect()
if device == "cuda":
    torch.cuda.empty_cache()
print("Cleanup complete.")

# --- Configuration Summary ---
print("\n--- Final Configuration Used ---")
print(f"Audio File: {audio_file}")
print(f"Device: {device}")
print(f"Compute Type: {compute_type}")
print(f"Batch Size: {batch_size}")
print(f"Whisper Model: {whisper_model_name}")
print(f"Language: {language_code}")
print("\nASR Options (for faster-whisper):")
for key, value in asr_options.items():
    print(f"  {key}: {value}")
print("\nVAD Options (using Silero VAD):")
for key, value in vad_options.items():
    print(f"  {key}: {value}")
print("\nTranscription Config (whisperx):")
for key, value in transcribe_config.items():
    print(f"  {key}: {value}")
print("\nAlignment Config (whisperx):")
print(f"  Return Char Alignments: {align_config['return_char_alignments']}")
print(f"  Print Progress: {align_config['print_progress']}")
print("---------------------------------")
